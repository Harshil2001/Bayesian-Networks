# -*- coding: utf-8 -*-
"""Copy of RandomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13DwLoVHnkmdePf47ZM2uzAj1Fz71F_Ci
"""

# # Unzipping the datasets if needed
# !unzip /content/datasets.zip -d /content/

from __future__ import print_function
import numpy as np
import sys
import time
import contextlib
from RandomForest_CLT import RandomForest_CLT
from Util import *
from CLT_class import CLT
import random
from sklearn.utils import resample
from collections import defaultdict
import os
import timeit


class RandomForest():
    def __init__(self):
        self.n_components = 0 # number of components
        self.mixture_probs = None # mixture probabilities
        self.clt_list =[]   # List of Tree Bayesian networks

    '''
        Learn Mixtures of Trees using the EM algorithm.
    '''
    def learn(self, dataset, n_components, r):
        
        self.n_components = n_components
        wt=np.ones((n_components,dataset.shape[0])) #Assuming equal weights for all values
        self.mixture_probs = [1/n_components]*n_components  #Pi as 1/k
    
        for k in range(n_components):
            self.clt_list.append(RandomForest_CLT())
        
        for k in range(n_components):
            resampled = resample(dataset)
            self.clt_list[k].learn(resampled)
            self.clt_list[k].update(resampled, wt[k], r)

    '''
        Compute the log-likelihood score of the dataset
    '''
    def computeLL(self, dataset):
        ll = 0.0
        for k in range(self.n_components):
            ll += self.clt_list[k].computeLL(dataset)
        return ll/dataset.shape[0] 

random_forest = RandomForest()

c = 0
index = defaultdict(list)
file_path="/content/dataset/"
for i, file in enumerate(sorted(os.listdir(file_path))):
    if(i % 3 == 0):
        c += 1
    index[c].append(file)

# # Validation - uncomment the next 10 lines for tuning the value of the hidden variable k and r
# for key, values in index.items():
#     print("FOr VALID-SET: ", index[key][1])
#     dataset=Util.load_dataset("/content/dataset/"+index[key][1])
#     validset = Util.load_dataset("/content/dataset/"+index[key][2])
#     testset=Util.load_dataset("/content/dataset/"+index[key][0])
#     k_values=[2]
#     r_values=[5, 10, 80, 120]
#     for k in k_values:
#         for r in r_values:
#             random_forest.learn(dataset, n_components=k, r = r)
#             print(validset.shape[0])
#             print(validset.shape[1])
#             print("When k=",k," AND r=",r," LL=",random_forest.computeLL(validset))

k_values = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
r_values = [5, 5, 120, 10, 5, 10, 5, 5, 120, 10]

for i in index:
    print("=================================================================================\n")
    print("FOR Dataset ",i,"\n\n")
    dataset=Util.load_dataset("/content/dataset/"+index[i][1])
    validset = Util.load_dataset("/content/dataset/"+index[i][2])
    testset=Util.load_dataset("/content/dataset/"+index[i][0])
    sum = 0
    ll_list = []
    for it in range(4):
      random_forest.learn(dataset, n_components=k_values[i-1], r = r_values[i-1])
      LL = random_forest.computeLL(validset)
      print("LL=", LL,"for it= ", it)
      ll_list.append(LL)
      sum += LL
    mean = sum/len(ll_list)
    print("Average is ", mean)
    sum = 0
    for j in ll_list:
      sum += (j-mean)**2
    sd = sum/len(ll_list)
    print("Standarad deviation is ", sd)